<!DOCTYPE html>
<html lang="it">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="Guida completa a SmartCoreAI - Libreria Delphi per integrazione AI">
    <meta name="color-scheme" content="light dark">
    <title>SmartCoreAI - Guida</title>
    <link rel="stylesheet" href="styles.css">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&family=JetBrains+Mono:wght@400;500&display=swap" rel="stylesheet">
</head>
<body>
    <nav class="sidebar" id="sidebar">
        <div class="sidebar-header">
            <div class="logo">
                <svg width="32" height="32" viewBox="0 0 32 32" fill="none" xmlns="http://www.w3.org/2000/svg">
                    <rect width="32" height="32" rx="8" fill="currentColor" class="logo-bg"/>
                    <path d="M8 16L14 10L20 16L14 22L8 16Z" fill="var(--bg-primary)"/>
                    <path d="M14 16L20 10L26 16L20 22L14 16Z" fill="var(--bg-primary)" opacity="0.6"/>
                </svg>
                <span class="logo-text">SmartCoreAI</span>
            </div>
            <button class="menu-toggle" id="menuToggle" aria-label="Toggle menu">
                <svg width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                    <line x1="3" y1="6" x2="21" y2="6"></line>
                    <line x1="3" y1="12" x2="21" y2="12"></line>
                    <line x1="3" y1="18" x2="21" y2="18"></line>
                </svg>
            </button>
        </div>
        <div class="sidebar-content" id="sidebarContent">
            <ul class="nav-list" id="navList">
                <!-- Generated by JavaScript -->
            </ul>
        </div>
        <div class="sidebar-footer">
            <button class="theme-toggle" id="themeToggle" aria-label="Toggle theme">
                <svg class="sun-icon" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                    <circle cx="12" cy="12" r="5"></circle>
                    <line x1="12" y1="1" x2="12" y2="3"></line>
                    <line x1="12" y1="21" x2="12" y2="23"></line>
                    <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                    <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                    <line x1="1" y1="12" x2="3" y2="12"></line>
                    <line x1="21" y1="12" x2="23" y2="12"></line>
                    <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                    <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                </svg>
                <svg class="moon-icon" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                    <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                </svg>
                <span class="theme-label">Tema</span>
            </button>
        </div>
    </nav>

    <main class="main-content">
        <header class="page-header">
            <h1>Guida a SmartCoreAI</h1>
            <p class="lead">SmartCoreAI e una libreria ufficiale Embarcadero per Delphi che fornisce un'interfaccia unificata per integrare diversi provider di intelligenza artificiale nelle applicazioni Delphi. Supporta VCL e FireMonkey su Windows, macOS, Linux, iOS e Android.</p>
        </header>

        <article class="content">
            <!-- Concetto di Driver -->
            <section id="concetto-di-driver">
                <h2>Concetto di Driver</h2>
                <p>Il <strong>driver</strong> e il componente centrale che implementa la comunicazione con uno specifico provider AI. Ogni driver implementa l'interfaccia <code>IAIDriver</code> e gestisce:</p>
                <ul>
                    <li>Autenticazione e configurazione specifica del provider</li>
                    <li>Serializzazione delle richieste nel formato atteso dall'API</li>
                    <li>Parsing delle risposte e normalizzazione degli errori</li>
                    <li>Gestione del threading e sincronizzazione degli eventi</li>
                </ul>
                <p>I driver sono intercambiabili: e possibile passare da OpenAI a Gemini semplicemente cambiando il driver associato alla connessione, mantenendo lo stesso codice applicativo.</p>

                <h3 id="architettura">Architettura Connection-Driver-Request</h3>
                <pre><code>TAIConnection (connessione)
    |
    +-- TAIDriver (driver specifico: OpenAI, Claude, Gemini, Ollama)
    |
    +-- TAIChatRequest / TAIImageRequest / TAIJSONRequest / TAIStreamRequest</code></pre>
                <p>La <code>TAIConnection</code> funge da contenitore che ospita un driver e lo rende disponibile ai componenti di richiesta. I componenti di richiesta (<code>TAIChatRequest</code>, <code>TAIImageRequest</code>, etc.) si collegano alla connessione e delegano l'esecuzione al driver attivo.</p>
            </section>

            <!-- Provider Supportati -->
            <section id="provider-supportati">
                <h2>Provider Supportati</h2>

                <h3 id="openai">OpenAI (TAIOpenAIDriver)</h3>
                <p><strong>Modello predefinito:</strong> <code>gpt-5</code></p>
                <div class="table-wrapper">
                    <table>
                        <thead>
                            <tr><th>Funzionalita</th><th>Supportata</th></tr>
                        </thead>
                        <tbody>
                            <tr><td>Chat/Conversazione</td><td class="supported">Si</td></tr>
                            <tr><td>Generazione immagini (DALL-E)</td><td class="supported">Si</td></tr>
                            <tr><td>Text-to-Speech</td><td class="supported">Si</td></tr>
                            <tr><td>Trascrizione audio (Whisper)</td><td class="supported">Si</td></tr>
                            <tr><td>Traduzione audio</td><td class="supported">Si</td></tr>
                            <tr><td>Fine-tuning</td><td class="supported">Si</td></tr>
                            <tr><td>Batch processing</td><td class="supported">Si</td></tr>
                            <tr><td>Moderazione contenuti</td><td class="supported">Si</td></tr>
                        </tbody>
                    </table>
                </div>
                <p><strong>Parametri principali:</strong></p>
                <ul>
                    <li><code>APIKey</code> - Chiave API OpenAI (obbligatoria)</li>
                    <li><code>Model</code> - Modello da utilizzare (es. <code>gpt-4.1</code>, <code>gpt-5</code>)</li>
                    <li><code>MaxToken</code> - Numero massimo di token nella risposta</li>
                    <li><code>Temperature</code> - Controllo creativita (0.0 - 2.0)</li>
                    <li><code>Stream</code> - Abilita risposte in streaming</li>
                </ul>

                <h3 id="claude">Claude/Anthropic (TAIClaudeDriver)</h3>
                <p><strong>Modello predefinito:</strong> <code>claude-sonnet-4-latest</code></p>
                <div class="table-wrapper">
                    <table>
                        <thead>
                            <tr><th>Funzionalita</th><th>Supportata</th></tr>
                        </thead>
                        <tbody>
                            <tr><td>Chat/Conversazione</td><td class="supported">Si</td></tr>
                            <tr><td>Generazione immagini</td><td class="not-supported">No</td></tr>
                            <tr><td>Vision (comprensione immagini)</td><td class="supported">Si</td></tr>
                            <tr><td>Batch processing</td><td class="supported">Si</td></tr>
                            <tr><td>Gestione file</td><td class="supported">Si</td></tr>
                        </tbody>
                    </table>
                </div>
                <p><strong>Parametri principali:</strong></p>
                <ul>
                    <li><code>APIKey</code> - Chiave API Anthropic (obbligatoria)</li>
                    <li><code>Model</code> - Modello da utilizzare (es. <code>claude-sonnet-4-latest</code>, <code>claude-3-opus-20240229</code>)</li>
                    <li><code>MaxToken</code> - Numero massimo di token</li>
                    <li><code>AnthropicVersion</code> - Versione API</li>
                </ul>

                <h3 id="gemini">Google Gemini (TAIGeminiDriver)</h3>
                <p><strong>Modello predefinito:</strong> <code>gemini-2.0-flash</code></p>
                <div class="table-wrapper">
                    <table>
                        <thead>
                            <tr><th>Funzionalita</th><th>Supportata</th></tr>
                        </thead>
                        <tbody>
                            <tr><td>Chat/Conversazione</td><td class="supported">Si</td></tr>
                            <tr><td>Generazione immagini</td><td class="supported">Si</td></tr>
                            <tr><td>Vision (comprensione immagini)</td><td class="supported">Si</td></tr>
                            <tr><td>Comprensione video</td><td class="supported">Si</td></tr>
                            <tr><td>Comprensione audio</td><td class="supported">Si</td></tr>
                            <tr><td>Text-to-Speech</td><td class="supported">Si</td></tr>
                            <tr><td>Comprensione documenti</td><td class="supported">Si</td></tr>
                        </tbody>
                    </table>
                </div>
                <p><strong>Parametri principali:</strong></p>
                <ul>
                    <li><code>APIKey</code> - Chiave API Google (obbligatoria)</li>
                    <li><code>Model</code> - Modello da utilizzare (es. <code>gemini-2.5-pro</code>, <code>gemini-2.0-flash</code>)</li>
                    <li><code>MaxToken</code> - Numero massimo di token</li>
                    <li><code>Temperature</code>, <code>TopK</code>, <code>TopP</code> - Parametri di sampling</li>
                </ul>

                <h3 id="ollama">Ollama (TAIOllamaDriver)</h3>
                <p><strong>Modello predefinito:</strong> <code>llama3.1:8b</code></p>
                <div class="table-wrapper">
                    <table>
                        <thead>
                            <tr><th>Funzionalita</th><th>Supportata</th></tr>
                        </thead>
                        <tbody>
                            <tr><td>Chat/Conversazione</td><td class="supported">Si</td></tr>
                            <tr><td>Generazione immagini</td><td class="not-supported">No</td></tr>
                            <tr><td>Vision (comprensione immagini)</td><td class="partial">Si (dipende dal modello)</td></tr>
                            <tr><td>Operazioni stream</td><td class="not-supported">No</td></tr>
                        </tbody>
                    </table>
                </div>
                <p><strong>Parametri principali:</strong></p>
                <ul>
                    <li><code>BaseURL</code> - URL del server Ollama (default: <code>http://localhost:11434/api</code>)</li>
                    <li><code>Model</code> - Modello locale da utilizzare</li>
                    <li><code>SystemPrompt</code> - Prompt di sistema</li>
                    <li><code>Raw</code> - Modalita raw per prompt personalizzati</li>
                </ul>
            </section>

            <!-- Comportamento con Funzioni Non Supportate -->
            <section id="funzioni-non-supportate">
                <h2>Comportamento con Funzioni Non Supportate</h2>
                <p>Quando si invoca una funzione su un driver che non la supporta, viene sollevata un'eccezione <code>EAIException</code> con un messaggio descrittivo. Ad esempio:</p>
                <ul>
                    <li><strong>Generazione immagini su Ollama/Claude:</strong> <code>"Image generation is not supported by Ollama driver"</code></li>
                    <li><strong>Operazioni stream su Ollama:</strong> <code>"Stream operations is not supported by Ollama driver"</code></li>
                    <li><strong>JSON strutturato non supportato:</strong> <code>"JSON Structured generation is not supported by [driver] driver"</code></li>
                </ul>
                <p>Per gestire correttamente questi casi, utilizzare un blocco try-except:</p>
                <pre><code class="language-pascal">try
  Connection.DriverIntf.GenerateImage(Request, Callback);
except
  on E: EAIException do
    ShowMessage('Operazione non supportata: ' + E.Message);
end;</code></pre>
            </section>

            <!-- Risposte JSON Strutturate -->
            <section id="json-strutturate">
                <h2>Risposte JSON Strutturate</h2>
                <p>E possibile richiedere all'AI di restituire risposte in formato JSON seguendo una struttura specifica. Il supporto varia a seconda del provider.</p>

                <h3 id="openai-json">OpenAI - JSON Mode</h3>
                <p>OpenAI supporta il <strong>JSON Mode</strong> che garantisce risposte JSON valide.</p>
                <p><strong>Configurazione tramite parametri del driver:</strong></p>
                <pre><code class="language-pascal">OpenAIDriver.Params.ResponseFormat := 'json_object';  // oppure 'text' (default)</code></pre>

                <p><strong>Configurazione tramite TOpenAIChatRequest:</strong></p>
                <pre><code class="language-pascal">uses
  SmartCoreAI.Driver.OpenAI.Models;

var
  ChatRequest: TOpenAIChatRequest;
begin
  ChatRequest := TOpenAIChatRequest.Create;
  try
    ChatRequest.Model := 'gpt-4.1';
    ChatRequest.Messages.Add(TAIChatMessage.Create(cmrUser,
      'Restituisci una lista di 3 colori con nome e codice hex in formato JSON: ' +
      '{"colori": [{"nome": "...", "hex": "..."}]}'));

    // Abilita JSON mode
    ChatRequest.ResponseFormat := TOpenAIResponseFormat.JSONObject;

    // ... esegui la richiesta
  finally
    ChatRequest.Free;
  end;
end;</code></pre>

                <p><strong>Tipi di ResponseFormat disponibili:</strong></p>
                <div class="table-wrapper">
                    <table>
                        <thead>
                            <tr><th>Classe</th><th>Descrizione</th></tr>
                        </thead>
                        <tbody>
                            <tr><td><code>TOpenAIResponseFormat.Text</code></td><td>Risposta testuale normale (default)</td></tr>
                            <tr><td><code>TOpenAIResponseFormat.JSONObject</code></td><td>Forza risposta in formato JSON valido</td></tr>
                        </tbody>
                    </table>
                </div>
                <div class="callout callout-info">
                    <strong>Nota importante:</strong> Con <code>json_object</code>, OpenAI garantisce che la risposta sia JSON sintatticamente valido, ma devi specificare nel prompt la struttura desiderata. Il modello seguira le istruzioni del prompt per la struttura dei dati.
                </div>

                <h3 id="gemini-json">Google Gemini - Structured Output con Schema</h3>
                <p>Gemini offre un supporto piu avanzato con classi dedicate per definire uno schema JSON:</p>
                <pre><code class="language-pascal">uses
  SmartCoreAI.Driver.Gemini.Models;

var
  Schema: TAIGeminiStructuredSchema;
  Field: TAIGeminiSchemaField;
begin
  Schema := TAIGeminiStructuredSchema.Create;
  try
    Schema.Title := 'Colore';
    Schema.&amp;Type := 'object';

    // Definisci i campi dello schema
    Field := TAIGeminiSchemaField.Create;
    Field.Name := 'nome';
    Field.&amp;Type := 'string';
    Field.Description := 'Nome del colore';
    Field.Required := True;
    Schema.Properties.Add(Field);

    Field := TAIGeminiSchemaField.Create;
    Field.Name := 'hex';
    Field.&amp;Type := 'string';
    Field.Description := 'Codice esadecimale del colore';
    Field.Required := True;
    Schema.Properties.Add(Field);

    // Usa lo schema nella richiesta...
  finally
    Schema.Free;
  end;
end;</code></pre>

                <p><strong>Classi per Structured Output in Gemini:</strong></p>
                <div class="table-wrapper">
                    <table>
                        <thead>
                            <tr><th>Classe</th><th>Descrizione</th></tr>
                        </thead>
                        <tbody>
                            <tr><td><code>TAIGeminiSchemaField</code></td><td>Definisce un singolo campo: Name, Type, Description, Required</td></tr>
                            <tr><td><code>TAIGeminiStructuredSchema</code></td><td>Schema completo con Title, Type e lista di Properties</td></tr>
                            <tr><td><code>TAIGeminiStructuredOutputConfig</code></td><td>Configurazione da passare alla richiesta</td></tr>
                        </tbody>
                    </table>
                </div>
                <p><strong>Tipi supportati per i campi:</strong> <code>string</code>, <code>number</code>, <code>boolean</code>, <code>array</code>, <code>object</code></p>

                <h3 id="claude-ollama-json">Claude e Ollama</h3>
                <p>Questi driver non hanno supporto nativo per JSON strutturato nella libreria. La strategia consigliata e:</p>
                <ol>
                    <li>Specificare chiaramente il formato JSON desiderato nel prompt</li>
                    <li>Parsare la risposta testuale</li>
                </ol>
                <pre><code class="language-pascal">// Esempio di prompt per Claude/Ollama
const
  Prompt = 'Restituisci SOLO un oggetto JSON valido (senza testo aggiuntivo) ' +
           'con questa struttura: {"colori": [{"nome": "string", "hex": "string"}]}. ' +
           'Elenca 3 colori.';</code></pre>

                <h3 id="estrazione-json">Estrazione JSON dalle Risposte</h3>
                <p>Quando l'AI restituisce JSON all'interno di blocchi di codice markdown (<code>```json ... ```</code>), usa <code>TAIUtil.ExtractJSONFromCodeFence</code>:</p>
                <pre><code class="language-pascal">uses
  System.JSON, SmartCoreAI.Types;

var
  ResponseText: string;
  JsonStr: string;
  JsonObj: TJSONObject;
begin
  // ResponseText contiene la risposta dell'AI, es:
  // "Ecco i colori richiesti:
  // ```json
  // {"colori": [{"nome": "rosso", "hex": "#FF0000"}]}
  // ```"

  // Estrai il JSON dal code fence
  JsonStr := TAIUtil.ExtractJSONFromCodeFence(ResponseText);

  // Se non c'era un code fence, JsonStr = ResponseText (passa attraverso)

  // Parsa il JSON
  JsonObj := TJSONObject.ParseJSONValue(JsonStr) as TJSONObject;
  try
    // Usa JsonObj...
  finally
    JsonObj.Free;
  end;
end;</code></pre>

                <h3 id="riepilogo-json">Riepilogo Supporto per Provider</h3>
                <div class="table-wrapper">
                    <table>
                        <thead>
                            <tr><th>Provider</th><th>JSON Mode</th><th>Schema Strutturato</th><th>Note</th></tr>
                        </thead>
                        <tbody>
                            <tr><td>OpenAI</td><td class="supported">Si (<code>TOpenAIResponseFormat.JSONObject</code>)</td><td class="not-supported">No</td><td>Struttura da specificare nel prompt</td></tr>
                            <tr><td>Gemini</td><td class="supported">Si</td><td class="supported">Si (<code>TAIGeminiStructuredSchema</code>)</td><td>Supporto schema completo</td></tr>
                            <tr><td>Claude</td><td class="not-supported">No</td><td class="not-supported">No</td><td>Usare istruzioni nel prompt</td></tr>
                            <tr><td>Ollama</td><td class="not-supported">No</td><td class="not-supported">No</td><td>Usare istruzioni nel prompt</td></tr>
                        </tbody>
                    </table>
                </div>
            </section>

            <!-- Chat Conversazionale -->
            <section id="chat-conversazionale">
                <h2>Chat Conversazionale (Multi-Turn)</h2>
                <p>La libreria supporta conversazioni multi-turn dove l'AI mantiene il contesto dei messaggi precedenti. Questo si ottiene usando il metodo <code>ChatEx</code> invece di <code>Chat</code>.</p>

                <h3 id="chat-vs-chatex">Differenza tra Chat e ChatEx</h3>
                <div class="table-wrapper">
                    <table>
                        <thead>
                            <tr><th>Metodo</th><th>Descrizione</th></tr>
                        </thead>
                        <tbody>
                            <tr><td><code>Chat(APrompt, ACallback)</code></td><td>Singolo turno - ogni chiamata e indipendente, senza memoria</td></tr>
                            <tr><td><code>ChatEx(ARequest)</code></td><td>Multi-turn - passa un oggetto richiesta con lo storico completo dei messaggi</td></tr>
                        </tbody>
                    </table>
                </div>

                <h3 id="openai-multiturn">OpenAI - Conversazione Multi-Turn</h3>
                <pre><code class="language-pascal">uses
  SmartCoreAI.Driver.OpenAI, SmartCoreAI.Driver.OpenAI.Models;

var
  Request: TOpenAIChatRequest;
  Driver: TAIOpenAIDriver;
begin
  Request := TOpenAIChatRequest.Create;
  try
    Request.Model := 'gpt-4.1';

    // Messaggio di sistema (opzionale, definisce il comportamento dell'AI)
    Request.Messages.Add(TAIChatMessage.Create(cmrSystem,
      'Sei un assistente esperto di programmazione Delphi.'));

    // Prima domanda dell'utente
    Request.Messages.Add(TAIChatMessage.Create(cmrUser,
      'Come creo una classe in Delphi?'));

    // Risposta dell'assistente (ottenuta dalla chiamata precedente)
    Request.Messages.Add(TAIChatMessage.Create(cmrAssistant,
      'Per creare una classe in Delphi usa la sintassi: type TMyClass = class...'));

    // Domanda di follow-up dell'utente
    Request.Messages.Add(TAIChatMessage.Create(cmrUser,
      'E come aggiungo un costruttore?'));

    // Esegui la richiesta - l'AI vedra tutto lo storico
    Driver.ChatEx(Request);
  finally
    Request.Free;
  end;
end;</code></pre>

                <p><strong>Ruoli disponibili (<code>TAIChatMessageRole</code>):</strong></p>
                <div class="table-wrapper">
                    <table>
                        <thead>
                            <tr><th>Ruolo</th><th>Descrizione</th></tr>
                        </thead>
                        <tbody>
                            <tr><td><code>cmrSystem</code></td><td>Istruzioni di sistema per definire il comportamento dell'AI</td></tr>
                            <tr><td><code>cmrUser</code></td><td>Messaggi dell'utente</td></tr>
                            <tr><td><code>cmrAssistant</code></td><td>Risposte precedenti dell'AI (da includere per mantenere il contesto)</td></tr>
                            <tr><td><code>cmrFunction</code></td><td>Risultati di function calling</td></tr>
                            <tr><td><code>cmrTool</code></td><td>Risultati di tool use</td></tr>
                        </tbody>
                    </table>
                </div>

                <h3 id="claude-multiturn">Claude - Conversazione Multi-Turn</h3>
                <pre><code class="language-pascal">uses
  SmartCoreAI.Driver.Claude, SmartCoreAI.Driver.Claude.Models;

var
  Request: TClaudeMessageRequest;
  Driver: TAIClaudeDriver;
begin
  Request := TClaudeMessageRequest.Create;
  try
    Request.Model := 'claude-sonnet-4-latest';
    Request.MaxTokens := 1024;

    // System prompt (proprieta separata in Claude, non un messaggio)
    Request.System := 'Sei un assistente esperto di programmazione Delphi.';

    // Storico della conversazione
    Request.Messages.Add(TClaudeMessage.Create('user',
      'Come creo una classe in Delphi?'));

    Request.Messages.Add(TClaudeMessage.Create('assistant',
      'Per creare una classe in Delphi usa la sintassi: type TMyClass = class...'));

    Request.Messages.Add(TClaudeMessage.Create('user',
      'E come aggiungo un costruttore?'));

    // Esegui
    Driver.ChatEx(Request);
  finally
    Request.Free;
  end;
end;</code></pre>
                <div class="callout callout-info">
                    <strong>Nota:</strong> In Claude i ruoli sono stringhe: <code>'user'</code> e <code>'assistant'</code>. Il system prompt e una proprieta separata (<code>Request.System</code>), non un messaggio.
                </div>

                <h3 id="conversation-manager">Pattern per Gestire una Conversazione</h3>
                <p>Per semplificare la gestione dello storico, puoi creare una classe helper:</p>
                <pre><code class="language-pascal">type
  TConversationManager = class
  private
    FRequest: TOpenAIChatRequest;
    FDriver: TAIOpenAIDriver;
  public
    constructor Create(ADriver: TAIOpenAIDriver; const AModel: string);
    destructor Destroy; override;

    procedure SetSystemPrompt(const APrompt: string);
    procedure AddUserMessage(const AMessage: string);
    procedure AddAssistantResponse(const AResponse: string);
    function Send: TGUID;
    procedure ClearHistory;
  end;

constructor TConversationManager.Create(ADriver: TAIOpenAIDriver; const AModel: string);
begin
  FDriver := ADriver;
  FRequest := TOpenAIChatRequest.Create;
  FRequest.Model := AModel;
end;

destructor TConversationManager.Destroy;
begin
  FRequest.Free;
  inherited;
end;

procedure TConversationManager.SetSystemPrompt(const APrompt: string);
begin
  // Il system prompt deve essere il primo messaggio
  if (FRequest.Messages.Count = 0) or
     (FRequest.Messages[0].Role &lt;&gt; cmrSystem) then
    FRequest.Messages.Insert(0, TAIChatMessage.Create(cmrSystem, APrompt))
  else
    FRequest.Messages[0].Content := APrompt;
end;

procedure TConversationManager.AddUserMessage(const AMessage: string);
begin
  FRequest.Messages.Add(TAIChatMessage.Create(cmrUser, AMessage));
end;

procedure TConversationManager.AddAssistantResponse(const AResponse: string);
begin
  // Aggiungi la risposta dell'AI allo storico per le prossime richieste
  FRequest.Messages.Add(TAIChatMessage.Create(cmrAssistant, AResponse));
end;

function TConversationManager.Send: TGUID;
begin
  Result := FDriver.ChatEx(FRequest);
end;

procedure TConversationManager.ClearHistory;
begin
  FRequest.Messages.Clear;
end;</code></pre>

                <h3 id="chat-interattiva">Esempio Completo di Chat Interattiva</h3>
                <pre><code class="language-pascal">type
  TFormChat = class(TForm)
    edtInput: TEdit;
    btnSend: TButton;
    memoChat: TMemo;
    AIConnection: TAIConnection;
    AIChatRequest: TAIChatRequest;
  private
    FConversation: TConversationManager;
    procedure OnChatResponse(Sender: TObject; const Text: string);
  public
    procedure FormCreate(Sender: TObject);
    procedure FormDestroy(Sender: TObject);
    procedure btnSendClick(Sender: TObject);
  end;

procedure TFormChat.FormCreate(Sender: TObject);
begin
  FConversation := TConversationManager.Create(
    AIConnection.Driver as TAIOpenAIDriver, 'gpt-4.1');
  FConversation.SetSystemPrompt('Sei un assistente amichevole e competente.');

  // Collega l'evento di risposta
  AIChatRequest.OnResponse := OnChatResponse;
end;

procedure TFormChat.FormDestroy(Sender: TObject);
begin
  FConversation.Free;
end;

procedure TFormChat.btnSendClick(Sender: TObject);
var
  UserInput: string;
begin
  UserInput := Trim(edtInput.Text);
  if UserInput = '' then Exit;

  // Mostra il messaggio dell'utente
  memoChat.Lines.Add('Tu: ' + UserInput);
  edtInput.Clear;

  // Aggiungi allo storico e invia
  FConversation.AddUserMessage(UserInput);
  FConversation.Send;
end;

procedure TFormChat.OnChatResponse(Sender: TObject; const Text: string);
begin
  // IMPORTANTE: aggiungi la risposta allo storico per mantenere il contesto
  FConversation.AddAssistantResponse(Text);

  // Mostra nella UI
  memoChat.Lines.Add('AI: ' + Text);
  memoChat.Lines.Add('');
end;</code></pre>

                <h3 id="considerazioni-storico">Considerazioni sullo Storico</h3>
                <ul>
                    <li><strong>Limite token:</strong> Ogni provider ha un limite massimo di token per richiesta. Se la conversazione diventa troppo lunga, dovrai rimuovere i messaggi piu vecchi.</li>
                    <li><strong>Costi:</strong> Piu messaggi nello storico = piu token inviati = costi maggiori.</li>
                    <li><strong>Context window:</strong> GPT-4 supporta fino a 128K token, Claude fino a 200K, Gemini fino a 1M.</li>
                </ul>
                <pre><code class="language-pascal">// Esempio: mantieni solo gli ultimi N messaggi (oltre al system prompt)
procedure TConversationManager.TrimHistory(MaxMessages: Integer);
var
  StartIndex: Integer;
begin
  // Preserva il system prompt se presente
  if (FRequest.Messages.Count > 0) and
     (FRequest.Messages[0].Role = cmrSystem) then
    StartIndex := 1
  else
    StartIndex := 0;

  // Rimuovi i messaggi piu vecchi
  while FRequest.Messages.Count - StartIndex > MaxMessages do
    FRequest.Messages.Delete(StartIndex);
end;</code></pre>
            </section>

            <!-- Embeddings -->
            <section id="embeddings">
                <h2>Embeddings (Workaround)</h2>
                <p>La libreria <strong>non include supporto nativo per il calcolo degli embeddings</strong>. Tuttavia, e possibile chiamare gli endpoint embeddings manualmente usando <code>TAIJSONRequest</code>.</p>

                <h3 id="cosa-sono-embeddings">Cosa sono gli Embeddings</h3>
                <p>Gli embeddings sono rappresentazioni vettoriali di testo che catturano il significato semantico. Sono utili per:</p>
                <ul>
                    <li>Ricerca semantica</li>
                    <li>Clustering di documenti</li>
                    <li>Sistemi di raccomandazione</li>
                    <li>Rilevamento di similarita</li>
                </ul>

                <h3 id="supporto-embeddings">Supporto Embeddings per Provider</h3>
                <div class="table-wrapper">
                    <table>
                        <thead>
                            <tr><th>Provider</th><th>Endpoint</th><th>Modelli</th></tr>
                        </thead>
                        <tbody>
                            <tr><td>OpenAI</td><td><code>/embeddings</code></td><td><code>text-embedding-3-small</code>, <code>text-embedding-3-large</code>, <code>text-embedding-ada-002</code></td></tr>
                            <tr><td>Gemini</td><td><code>/models/{model}:embedContent</code></td><td><code>text-embedding-004</code></td></tr>
                            <tr><td>Ollama</td><td><code>/api/embeddings</code></td><td>Dipende dai modelli installati (es. <code>nomic-embed-text</code>)</td></tr>
                            <tr><td>Claude</td><td colspan="2">Non supportato</td></tr>
                        </tbody>
                    </table>
                </div>

                <h3 id="embeddings-openai">Esempio: Embeddings con OpenAI</h3>
                <pre><code class="language-pascal">uses
  System.JSON, SmartCoreAI.Comp.JSON, SmartCoreAI.Comp.Connection;

type
  TForm1 = class(TForm)
    AIConnection: TAIConnection;
    AIJSONRequest: TAIJSONRequest;
    procedure AIJSONRequestSuccess(Sender: TObject; const Response: string);
    procedure AIJSONRequestError(Sender: TObject; const ErrorMessage: string);
  public
    procedure GetEmbedding(const AText: string);
    procedure GetEmbeddingsBatch(const ATexts: TArray&lt;string&gt;);
  end;

// Embedding singolo
procedure TForm1.GetEmbedding(const AText: string);
var
  Params: TJSONObject;
begin
  Params := TJSONObject.Create;
  try
    Params.AddPair('model', 'text-embedding-3-small');
    Params.AddPair('input', AText);

    AIJSONRequest.Endpoint := '/embeddings';
    AIJSONRequest.Params := Params.ToString;
    AIJSONRequest.Execute;
  finally
    Params.Free;
  end;
end;

// Embedding batch (piu testi in una sola chiamata)
procedure TForm1.GetEmbeddingsBatch(const ATexts: TArray&lt;string&gt;);
var
  Params: TJSONObject;
  InputArray: TJSONArray;
  Text: string;
begin
  Params := TJSONObject.Create;
  InputArray := TJSONArray.Create;
  try
    for Text in ATexts do
      InputArray.Add(Text);

    Params.AddPair('model', 'text-embedding-3-small');
    Params.AddPair('input', InputArray);

    AIJSONRequest.Endpoint := '/embeddings';
    AIJSONRequest.Params := Params.ToString;
    AIJSONRequest.Execute;
  finally
    Params.Free; // InputArray viene liberato con Params
  end;
end;

procedure TForm1.AIJSONRequestSuccess(Sender: TObject; const Response: string);
var
  JSON: TJSONObject;
  DataArray: TJSONArray;
  DataItem: TJSONObject;
  EmbeddingArray: TJSONArray;
  I, J: Integer;
  Vector: TArray&lt;Double&gt;;
begin
  JSON := TJSONObject.ParseJSONValue(Response) as TJSONObject;
  try
    DataArray := JSON.GetValue('data') as TJSONArray;

    // Itera su ogni embedding (in caso di batch)
    for I := 0 to DataArray.Count - 1 do
    begin
      DataItem := DataArray.Items[I] as TJSONObject;
      EmbeddingArray := DataItem.GetValue('embedding') as TJSONArray;

      // Converti in array di Double
      SetLength(Vector, EmbeddingArray.Count);
      for J := 0 to EmbeddingArray.Count - 1 do
        Vector[J] := EmbeddingArray.Items[J].AsType&lt;Double&gt;;

      // Usa Vector (es. salva in database, calcola similarita, etc.)
      // Vector contiene tipicamente 1536 dimensioni per text-embedding-3-small
    end;
  finally
    JSON.Free;
  end;
end;

procedure TForm1.AIJSONRequestError(Sender: TObject; const ErrorMessage: string);
begin
  ShowMessage('Errore embeddings: ' + ErrorMessage);
end;</code></pre>

                <h3 id="embeddings-ollama">Esempio: Embeddings con Ollama</h3>
                <pre><code class="language-pascal">procedure TForm1.GetEmbeddingOllama(const AText: string);
var
  Params: TJSONObject;
begin
  Params := TJSONObject.Create;
  try
    Params.AddPair('model', 'nomic-embed-text');
    Params.AddPair('prompt', AText);

    // Ollama usa un endpoint diverso
    AIJSONRequest.Endpoint := '/embeddings';
    AIJSONRequest.Params := Params.ToString;
    AIJSONRequest.Execute;
  finally
    Params.Free;
  end;
end;</code></pre>

                <h3 id="cosine-similarity">Calcolo della Similarita tra Vettori</h3>
                <p>Una volta ottenuti gli embeddings, puoi calcolare la similarita coseno:</p>
                <pre><code class="language-pascal">function CosineSimilarity(const A, B: TArray&lt;Double&gt;): Double;
var
  DotProduct, NormA, NormB: Double;
  I: Integer;
begin
  if Length(A) &lt;&gt; Length(B) then
    raise Exception.Create('I vettori devono avere la stessa dimensione');

  DotProduct := 0;
  NormA := 0;
  NormB := 0;

  for I := 0 to High(A) do
  begin
    DotProduct := DotProduct + A[I] * B[I];
    NormA := NormA + A[I] * A[I];
    NormB := NormB + B[I] * B[I];
  end;

  if (NormA = 0) or (NormB = 0) then
    Result := 0
  else
    Result := DotProduct / (Sqrt(NormA) * Sqrt(NormB));
end;

// Utilizzo
var
  Similarity: Double;
begin
  Similarity := CosineSimilarity(Vector1, Vector2);
  // Similarity va da -1 (opposti) a 1 (identici)
  // Valori > 0.8 indicano alta similarita semantica
end;</code></pre>
            </section>

            <!-- Tipi di Request -->
            <section id="tipi-request">
                <h2>Tipi di Request</h2>

                <h3 id="taichatrequest">TAIChatRequest</h3>
                <p>Componente per operazioni di chat/conversazione con l'AI.</p>
                <p><strong>Utilizzo:</strong> Invio di prompt testuali e ricezione di risposte.</p>
                <p><strong>Metodo principale:</strong></p>
                <ul>
                    <li><code>Chat(APrompt: string): TGUID</code> - Invia un prompt e restituisce un ID richiesta per eventuale cancellazione</li>
                </ul>
                <p><strong>Eventi:</strong></p>
                <ul>
                    <li><code>OnBeforeRequest</code> - Prima dell'invio della richiesta HTTP</li>
                    <li><code>OnAfterRequest</code> - Dopo l'invio della richiesta</li>
                    <li><code>OnBeforeResponse</code> - Prima dell'elaborazione della risposta</li>
                    <li><code>OnAfterResponse</code> - Dopo l'elaborazione della risposta</li>
                    <li><code>OnResponse(Text: string)</code> - Risposta testuale finale</li>
                    <li><code>OnPartialResponse(PartialText: string)</code> - Chunk di risposta in streaming</li>
                    <li><code>OnFullResponse(FullJsonResponse: string)</code> - JSON completo della risposta</li>
                    <li><code>OnError(ErrorMessage: string)</code> - Errore durante l'operazione</li>
                </ul>
                <div class="callout callout-warning">
                    <strong>Nota:</strong> Non chiamare <code>Execute</code> su questo componente; usare sempre <code>Chat()</code>.
                </div>

                <h3 id="taijsonrequest">TAIJSONRequest</h3>
                <p>Componente per richieste JSON generiche verso endpoint personalizzati.</p>
                <p><strong>Utilizzo:</strong> Chiamate a endpoint specifici del provider (moderazione, fine-tuning, gestione file, batch).</p>
                <p><strong>Proprieta:</strong></p>
                <ul>
                    <li><code>Endpoint: string</code> - Endpoint relativo (es. <code>/moderations</code>, <code>/files</code>)</li>
                    <li><code>Params: string</code> - Body JSON della richiesta</li>
                    <li><code>DataSet: TDataSet</code> - Dataset opzionale per mappare risultati JSON</li>
                </ul>
                <p><strong>Metodo principale:</strong></p>
                <ul>
                    <li><code>Execute: TGUID</code> - Esegue la richiesta JSON</li>
                </ul>
                <p><strong>Eventi:</strong></p>
                <ul>
                    <li><code>OnSuccess(Response: string)</code> - JSON di risposta</li>
                    <li><code>OnError(ErrorMessage: string)</code> - Errore</li>
                </ul>
                <p><strong>Metodo speciale:</strong></p>
                <ul>
                    <li><code>PopulateDataset(JSONObject)</code> - Popola il DataSet con array JSON trovati nella risposta</li>
                </ul>

                <h3 id="taistreamrequest">TAIStreamRequest</h3>
                <p>Componente per operazioni basate su stream (audio, video, documenti).</p>
                <p><strong>Utilizzo:</strong> Upload di file e ricezione di risultati elaborati (trascrizione audio, comprensione video, TTS).</p>
                <p><strong>Proprieta:</strong></p>
                <ul>
                    <li><code>Endpoint: string</code> - Endpoint relativo</li>
                    <li><code>InputFileName: string</code> - Percorso del file da inviare (deve esistere)</li>
                    <li><code>Params: TJSONObject</code> - Parametri JSON aggiuntivi (il componente ne fa una copia)</li>
                </ul>
                <p><strong>Metodo principale:</strong></p>
                <ul>
                    <li><code>Execute: TGUID</code> - Esegue l'operazione stream</li>
                </ul>
                <p><strong>Eventi:</strong></p>
                <ul>
                    <li><code>OnSuccess(AStream: TStream)</code> - Stream risultante dall'elaborazione</li>
                    <li><code>OnPartial(APartialData: TBytes)</code> - Dati parziali durante lo streaming progressivo</li>
                    <li><code>OnError(ErrorMessage: string)</code> - Errore</li>
                </ul>

                <h3 id="taiimagerequest">TAIImageRequest</h3>
                <p>Componente per la generazione di immagini.</p>
                <p><strong>Utilizzo:</strong> Creazione di immagini tramite AI (DALL-E, Gemini).</p>
                <p><strong>Proprieta:</strong></p>
                <ul>
                    <li><code>APIRequestObject: IAIImageGenerationRequest</code> - Oggetto richiesta con parametri (prompt, dimensioni, etc.)</li>
                    <li><code>DecodeMode: TAIImageDecodeMode</code> - Modalita decodifica (Auto, Base64, URL, None)</li>
                </ul>
                <p><strong>Metodo principale:</strong></p>
                <ul>
                    <li><code>Execute: TGUID</code> - Esegue la generazione</li>
                </ul>
                <p><strong>Eventi:</strong></p>
                <ul>
                    <li><code>OnSuccess(Images: TArray&lt;IAIImageGenerationResult&gt;; FullJsonResponse: string)</code> - Array di immagini generate</li>
                    <li><code>OnError(ErrorMessage: string)</code> - Errore</li>
                </ul>
            </section>

            <!-- Classi e Metodi Principali -->
            <section id="classi-metodi">
                <h2>Classi e Metodi Principali</h2>

                <h3 id="taiconnection">TAIConnection</h3>
                <p>Componente centrale di connessione.</p>
                <div class="table-wrapper">
                    <table>
                        <thead>
                            <tr><th>Metodo/Proprieta</th><th>Descrizione</th></tr>
                        </thead>
                        <tbody>
                            <tr><td><code>Driver: TAIDriver</code></td><td>Driver AI assegnato</td></tr>
                            <tr><td><code>DriverIntf: IAIDriver</code></td><td>Interfaccia del driver attivo</td></tr>
                            <tr><td><code>HttpClientCustomizer</code></td><td>Callback per personalizzare THTTPClient (TLS, proxy, headers, timeout)</td></tr>
                        </tbody>
                    </table>
                </div>

                <h3 id="taidriver">TAIDriver (classe base astratta)</h3>
                <p>Classe base per tutti i driver.</p>
                <div class="table-wrapper">
                    <table>
                        <thead>
                            <tr><th>Metodo/Proprieta</th><th>Descrizione</th></tr>
                        </thead>
                        <tbody>
                            <tr><td><code>GetDriverName: string</code></td><td>Nome del driver (es. "OpenAI", "Claude")</td></tr>
                            <tr><td><code>TestConnection(out AResponse): Boolean</code></td><td>Verifica la connessione al provider</td></tr>
                            <tr><td><code>LoadModels: TArray&lt;string&gt;</code></td><td>Carica l'elenco dei modelli disponibili</td></tr>
                            <tr><td><code>Chat(APrompt, ACallback): TGUID</code></td><td>Esegue una richiesta chat</td></tr>
                            <tr><td><code>GenerateImage(ARequest, ACallback): TGUID</code></td><td>Genera immagini</td></tr>
                            <tr><td><code>ExecuteJSONRequest(AEndpoint, AParams, ACallback): TGUID</code></td><td>Richiesta JSON generica</td></tr>
                            <tr><td><code>ProcessStream(AEndpoint, AInput, AParams, ACallback): TGUID</code></td><td>Elaborazione stream</td></tr>
                            <tr><td><code>Cancel(AId: TGUID)</code></td><td>Annulla una richiesta specifica</td></tr>
                            <tr><td><code>CancelAll</code></td><td>Annulla tutte le richieste in corso</td></tr>
                            <tr><td><code>Params: TAIDriverParams</code></td><td>Parametri di configurazione del driver</td></tr>
                            <tr><td><code>SynchronizeEvents: Boolean</code></td><td>Se True, gli eventi sono sincronizzati sul thread principale</td></tr>
                            <tr><td><code>IsRuning: Boolean</code></td><td>True se ci sono richieste attive</td></tr>
                        </tbody>
                    </table>
                </div>

                <h3 id="taidriverregistry">TAIDriverRegistry</h3>
                <p>Factory per la creazione dinamica dei driver.</p>
                <div class="table-wrapper">
                    <table>
                        <thead>
                            <tr><th>Metodo</th><th>Descrizione</th></tr>
                        </thead>
                        <tbody>
                            <tr><td><code>RegisterDriver(Name, DisplayName, Description, Category, Factory)</code></td><td>Registra un driver con factory</td></tr>
                            <tr><td><code>RegisterDriverClass(Name, DisplayName, Description, Category, AClass)</code></td><td>Registra una classe driver</td></tr>
                            <tr><td><code>CreateDriver(Name, Owner): IAIDriver</code></td><td>Crea un'istanza di driver per nome</td></tr>
                            <tr><td><code>RegisteredDrivers: TArray&lt;string&gt;</code></td><td>Elenco dei driver registrati</td></tr>
                            <tr><td><code>GetDriverMetadata(Name): TAIDriverMetadata</code></td><td>Metadati di un driver</td></tr>
                            <tr><td><code>GetAllMetadata: TArray&lt;TAIDriverMetadata&gt;</code></td><td>Tutti i metadati disponibili</td></tr>
                        </tbody>
                    </table>
                </div>

                <h3 id="taiutil">TAIUtil (helper in SmartCoreAI.Types.pas)</h3>
                <p>Utility statiche per operazioni comuni.</p>
                <div class="table-wrapper">
                    <table>
                        <thead>
                            <tr><th>Metodo</th><th>Descrizione</th></tr>
                        </thead>
                        <tbody>
                            <tr><td><code>DetectMimeType(Stream): string</code></td><td>Rileva il MIME type da firma binaria (PNG, JPEG, GIF, WebP, etc.)</td></tr>
                            <tr><td><code>DownloadImage(URL, Stream)</code></td><td>Scarica un'immagine da URL</td></tr>
                            <tr><td><code>ExtractJSONFromCodeFence(Text): string</code></td><td>Estrae JSON da blocchi di codice markdown</td></tr>
                            <tr><td><code>FindArray(JSONValue, Path): TJSONArray</code></td><td>Cerca ricorsivamente un array JSON</td></tr>
                            <tr><td><code>FindObject(JSONValue, Path): TJSONObject</code></td><td>Cerca ricorsivamente un oggetto JSON</td></tr>
                            <tr><td><code>SafeURLCompose(Base, Path): string</code></td><td>Compone URL evitando doppi slash</td></tr>
                            <tr><td><code>IsSuccessfulResponse(Response): Boolean</code></td><td>Verifica se la risposta HTTP e un successo (2xx)</td></tr>
                            <tr><td><code>ExtractErrorMessage(JSON): string</code></td><td>Estrae il messaggio di errore da risposte provider</td></tr>
                        </tbody>
                    </table>
                </div>
            </section>

            <!-- Bind Source per LiveBindings -->
            <section id="livebindings">
                <h2>Bind Source per LiveBindings</h2>
                <p>I BindSource permettono di collegare le risposte AI direttamente ai controlli UI tramite LiveBindings.</p>

                <h3 id="taichatbindsource">TAIChatBindSource</h3>
                <p>Collega le risposte chat a controlli LiveBindings.</p>
                <p><strong>Setup:</strong></p>
                <pre><code class="language-pascal">ChatBindSource.SetChatRequest(MyChatRequest);</code></pre>
                <p><strong>Comportamento:</strong> Quando arriva una risposta chat, viene aggiunto un <code>TChatResponseItem</code> alla lista interna. La lista viene esposta tramite <code>TListBindSourceAdapter</code> per il binding a ListView, Memo, etc.</p>
                <p><strong>Proprieta bindabili:</strong> <code>Text</code> (testo della risposta)</p>

                <h3 id="taijsonbindsource">TAIJSONBindSource</h3>
                <p>Collega le risposte JSON a controlli LiveBindings.</p>
                <p><strong>Setup:</strong></p>
                <pre><code class="language-pascal">JSONBindSource.SetJSONRequest(MyJSONRequest);</code></pre>
                <p><strong>Comportamento:</strong> Le risposte JSON vengono wrappate in <code>TJSONResponseItem</code> e aggiunte alla lista.</p>
                <p><strong>Proprieta bindabili:</strong> <code>JSONText</code> (JSON serializzato come stringa)</p>

                <h3 id="taistreambindsource">TAIStreamBindSource</h3>
                <p>Collega i risultati stream a controlli LiveBindings.</p>
                <p><strong>Setup:</strong></p>
                <pre><code class="language-pascal">StreamBindSource.SetStreamRequest(MyStreamRequest);</code></pre>
                <p><strong>Comportamento:</strong> Lo stream risultante viene convertito in testo e wrappato in <code>TStreamResponseItem</code>.</p>
                <p><strong>Proprieta bindabili:</strong> <code>Text</code> (contenuto dello stream come testo)</p>

                <h3 id="taiimagebindsource">TAIImageBindSource (solo FireMonkey)</h3>
                <p>Collega i risultati di generazione immagini a controlli FMX.</p>
                <p><strong>Setup:</strong></p>
                <pre><code class="language-pascal">ImageBindSource.SetResults(ImagesArray);</code></pre>
                <p><strong>Proprieta:</strong></p>
                <ul>
                    <li><code>AutoDownloadFromURL: Boolean</code> - Se True, scarica automaticamente immagini da URL</li>
                    <li><code>OnDownloadStream: TDownloadStreamEvent</code> - Hook personalizzato per download</li>
                </ul>
                <p><strong>Comportamento:</strong> I risultati <code>IAIImageGenerationResult</code> vengono convertiti in <code>TImageResponseItemFMX</code> contenenti un <code>TBitmap</code> FMX.</p>
                <p><strong>Proprieta bindabili:</strong> <code>Bitmap</code> (TBitmap FMX), <code>MimeType</code>, <code>ImageURL</code></p>
            </section>

            <!-- Gerarchia delle Eccezioni -->
            <section id="eccezioni">
                <h2>Gerarchia delle Eccezioni</h2>
                <pre><code>EAIException (base)
|-- EAIConfigException      - Errori di configurazione (chiavi mancanti, endpoint invalidi)
|-- EAIValidationException  - Errori di validazione input (prompt vuoto, parametri invalidi)
|-- EAIJSONException        - Errori di parsing JSON
|-- EAITransportException   - Errori di trasporto
|   |-- EAIHTTPException    - Errori HTTP con StatusCode, ResponseBody, RetryAfterSeconds
|   |   |-- EAIAuthException      - Errori 401/403 (autenticazione/autorizzazione)
|   |   +-- EAIRateLimitException - Errori 429 (rate limiting)
|   +-- EAITimeoutException - Timeout di connessione/lettura
+-- EAIRegisterException    - Errori di registrazione driver</code></pre>
                <p><strong>Metodo utile:</strong> <code>EAIException.ReraiseOrWrap(E, Context)</code> - Rilancia se gia un'eccezione AI, altrimenti la wrappa aggiungendo contesto.</p>
            </section>
        </article>

        <footer class="page-footer">
            <p>SmartCoreAI Documentation</p>
        </footer>
    </main>

    <button class="scroll-top" id="scrollTop" aria-label="Scroll to top">
        <svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
            <polyline points="18 15 12 9 6 15"></polyline>
        </svg>
    </button>

    <script src="script.js"></script>
</body>
</html>
